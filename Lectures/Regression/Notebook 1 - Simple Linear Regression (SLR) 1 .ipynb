{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression (SLR) 1\n",
    "\n",
    "## What We'll Accomplish in This Notebook\n",
    "\n",
    "<ul>\n",
    "    <li>Introduce the idea behind regression tasks.</li>\n",
    "    <li>Introduce the simple linear regression model with baseball data.</li>\n",
    "    <li>Start learning about more general machine learning/data science principles including:</li>\n",
    "        <ul>\n",
    "            <li>The statistical learning framework,</li>\n",
    "            <li>The train test split, and</li>\n",
    "            <li>Loss or cost functions.</li>\n",
    "        </ul>\n",
    "    <li>Have you build a simple linear regression model to predict carseat sales.</li>\n",
    "</ul>\n",
    "\n",
    "Let's Get Started! First we'll import the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As will become standard in all notebooks\n",
    "# we will import the following packages \n",
    "# We'll use these throughout the notebook so it is\n",
    "# good practice to import them before we get started\n",
    "\n",
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's notebook will be slightly different. Since this is our first step into the world of data science and machine learning we'll have to clear the brush a bit and introduce some machine learning concepts that will apply to all of our supervised learning methods. This means slightly more lecturing than normal.\n",
    "\n",
    "## What is Regression?\n",
    "\n",
    "### A Statistical Learning Framework\n",
    "\n",
    "Before discussing regression let's take a step back and talk about the more general <i>Statistical Learning</i> framework that encompasses regression in the light of <i>predictive modeling</i>.\n",
    "\n",
    "Suppose there is something that you'd like to predict. For example movie revenue given the film's budget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "\n",
    "plt.scatter(movies.budget/(10**6),movies.revenue/(10**6),alpha=.9,s=50)\n",
    "\n",
    "plt.xlabel(\"Budget in Millions of Dollars\",fontsize = 16)\n",
    "plt.ylabel(\"Revenue in Millions of Dollars\",fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or maybe predict a college's graduation rate given their student to faculty ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = pd.read_csv(\"college.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "\n",
    "plt.scatter(college['s_f_ratio'],college['grad_rate'],s=50)\n",
    "\n",
    "plt.xlabel(\"Student Faculty Ratio\",fontsize = 16)\n",
    "plt.ylabel(\"Graduation Rate (%)\",fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to approach these problems is to use statistical learning. In general we call the thing we want to predict $y$ and collect all of the data we'll use to predict $y$ into a matrix $X$ called the <i>feature matrix</i>. \n",
    "\n",
    "The idea behind statistical learning is that there is some true relationship between $X$ and $y$ that is obscured by random noise. This leads to a statistical model:\n",
    "$$\n",
    "y = f(X) + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon$ is random noise with mean zero.\n",
    "\n",
    "Let's illustrate this with a picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some data\n",
    "# x is evenly spaced from (-5,5)\n",
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "# y is f(x) + random noise\n",
    "y = 1/(1+np.exp(-x)) +  .08*np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The True Relationship Above is:\n",
    "$$\n",
    "y = \\frac{1}{1+e^{-x}}, \\text{ so } f(x) = \\frac{1}{1+e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "# make the figure\n",
    "fig,ax = plt.subplots(1,3,figsize = (16,10),sharey=True)\n",
    "\n",
    "# plot the truth\n",
    "ax[0].plot(x,1/(1+np.exp(-x)),linewidth=3,c='k',alpha=1,label=\"True Relationship\")\n",
    "\n",
    "# plot the data and the truth in the middle\n",
    "ax[1].plot(x,1/(1+np.exp(-x)),linewidth=3,c='k',alpha=.6,label=\"True Relationship\")\n",
    "ax[1].scatter(x,y,label = \"Observed Data\")\n",
    "\n",
    "# plot a sample estimate function on right\n",
    "ax[2].plot(x,.9/(1+.8*np.exp(-x))+.025,linewidth = 3,c='r',label=\"Estimated Relationship\")\n",
    "ax[2].plot(x,1/(1+np.exp(-x)),linewidth=3,c='k',alpha=.4,label=\"True Relationship\")\n",
    "ax[2].scatter(x,y,alpha=.8,label = \"Observed Date\")\n",
    "\n",
    "# Set titles and label\n",
    "ax[0].set_title(\"The Hidden Truth\",fontsize=18)\n",
    "ax[0].set_xlabel(\"X\",fontsize=16)\n",
    "ax[0].set_ylabel(\"y\",fontsize=16)\n",
    "\n",
    "ax[1].set_title(\"The Data, What We See\",fontsize=18)\n",
    "ax[1].set_xlabel(\"X\",fontsize=16)\n",
    "ax[1].set_ylabel(\"y\",fontsize=16)\n",
    "\n",
    "ax[2].set_title(\"The Estimate, Our Best Guess\",fontsize=18)\n",
    "ax[2].set_xlabel(\"X\",fontsize=16)\n",
    "ax[2].set_ylabel(\"y\",fontsize=16)\n",
    "\n",
    "# Add legends\n",
    "ax[0].legend(fontsize=14)\n",
    "ax[1].legend(fontsize=14)\n",
    "ax[2].legend(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to get as close as we can to the true relationship using the data we collect. Statistical Learning is all about estimating the true relationship the best we can. \n",
    "\n",
    "We often call the estimate of the relationship $\\hat{f}$. We'll see what it means to estimate this <i>the best we can</i> in a bit.\n",
    "\n",
    "### Just Answer the Question Already, What is Regression?\n",
    "\n",
    "In the world of predictive modeling, <b>regression</b> is a name we give problems where we'd like to estimate $f$ for quantitative $y$ data. So our first two examples, the movie revenue and the graduation rate would be regression problems. In these problems we often say that we're <i>regressing $y$ on $X$</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Break!\n",
    "\n",
    "Let's break for one or two minutes, I'll answer a couple of questions about what we just went over, and you can take a quick reddit break. Then we'll refocus for the next chunk on regression.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Break Over!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright let's now talk about our first regression method.\n",
    "\n",
    "## Simple Linear Regression\n",
    "\n",
    "We'll learn the method by solving a specific problem.\n",
    "\n",
    "You work for ESPN and you think that you can predict a baseball team's win total if you know their run differential. \n",
    "\n",
    "<i>For non-baseball fans a run is considered $1$ point in baseball, and run differential is the number of runs your team scores, denoted as $r$, minus the number of runs your team gave up, denoted as $ra$ for runs allowed, so run differential is $rd = r - ra$.</i>\n",
    "\n",
    "This is a regression problem, we want to predict a quantitative outcome, wins, using some feature, run differential.\n",
    "\n",
    "Let's look at some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to import the data\n",
    "# it is stored in the baseball_run_diff.csv file\n",
    "baseball = pd.read_csv(\"baseball_run_diff.csv\")\n",
    "\n",
    "\n",
    "# This will tell us about the df\n",
    "print(\"There are\",len(baseball),\"observations in the baseball df.\")\n",
    "print(\"The columns are\",list(baseball.columns))\n",
    "\n",
    "# Look at 5 randomly sampled rows\n",
    "baseball.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ML Aside - First Step in ML Data Handling, Train Test Split\n",
    "\n",
    "We've imported the baseball data we'll need. Now you may be tempted to start exploring this data. However, since we'll be building a predictive model on top of it we want to set aside a small subset of the data aside for testing purposes. This is known as making the <i>train test split</i>.\n",
    "\n",
    "The <i>train set</i> is the one we build our model on. A machine learning algorithm uses the train set to estimate the true relationship the best it can. \n",
    "\n",
    "<b>But what do we really care about? Making good predictions.</b> \n",
    "\n",
    "Good performance on the training data does not guarantee good predictive performance. So in order to get a sense of how good a particular model is we set aside a <i>test set</i> at the beginning of the model building process. This subset of the total data set is meant to allow you to test your model on data it didn't train on, therefore allowing you to simulate predicting on entirely new data. Typically this data isn't touched until the end of the model building process.\n",
    "\n",
    "##### ML Aside Over\n",
    "\n",
    "So let's use `pandas` to make our train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a copy of the original dataframe\n",
    "# this is due to the way python internally \n",
    "# stores objects\n",
    "baseball_copy = baseball.copy()\n",
    "\n",
    "# Now use sample to make a random sample\n",
    "# frac allows us to choose a fraction of the df\n",
    "# it is common to set aside 25% for testing\n",
    "baseball_train = baseball_copy.sample(frac = .75, random_state = 440)\n",
    "\n",
    "# now use drop and the train index to make test\n",
    "baseball_test = baseball_copy.drop(baseball_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at the training set head\n",
    "baseball_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore!\n",
    "\n",
    "Let's examine any potential relationship between wins (coded as `W`) and run differential (coded as `RD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use plt.scatter for this\n",
    "\n",
    "# first make a figure\n",
    "# this makes a figure that is 10 units by 10 units\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "# plt.scatter plots RD on the x and W on the y\n",
    "plt.scatter(baseball_train.RD, baseball_train.W)\n",
    "\n",
    "# Always good practice to label well when\n",
    "# presenting a figure to others\n",
    "# place an xlabel\n",
    "plt.xlabel(\"Run Differential\", fontsize =16)\n",
    "\n",
    "# place a ylabel\n",
    "plt.ylabel(\"Wins\", fontsize = 16)\n",
    "\n",
    "# type this to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write Something\n",
    "\n",
    "Let's take a moment to describe what relationship you see between run differential and wins. This will help us determine an appropriate model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use that relationship we just discussed.\n",
    "\n",
    "### The SLR Model\n",
    "\n",
    "Copying the notation of our dataframe let $w$ denote wins and $rd$ denote run differential, also assume we have $n$ observations. \n",
    "\n",
    "For Simple Linear Regression we model the true relationship as a straight line, let the subscript $i$ denote the $i_{\\text{th}}$ observation:\n",
    "$$\n",
    "w_i = \\beta_0 + \\beta_1 rd_i + \\epsilon_i,\n",
    "$$\n",
    "here $\\beta_0$ and $\\beta_1$ are coefficients we'll need to estimate, and $\\epsilon_i$ is random noise assumed to be an independent normally distributed with mean $0$ and standard deviation $\\sigma$. Note that we assume the same formula holds for all observations.\n",
    "\n",
    "#### Estimating the Model - What is \"Best\"\n",
    "\n",
    "We need to choose $\\beta_0$ and $\\beta_1$ so that the line we produce is the \"best\", but what does \"best\" mean. In general it means that we don't want our estimated line to be too far from the data. A common measure used in regression problems is the <i>Mean Square Error (MSE)</i> or equivalently the <i>Root Mean Square Error</i> (=$\\sqrt{\\text{MSE}}$). \n",
    "\n",
    "Suppose that we decide that $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ are the best estimates, then the MSE for those estimates is\n",
    "$$\n",
    "MSE = \\frac{1}{n}\\sum_{i=1}^n(\\hat{w_i} - w_i)^2 = \\frac{1}{n}\\sum_{i=1}^n(\\hat{\\beta_0} + \\hat{\\beta_1}rd_i - w_i)^2.\n",
    "$$\n",
    "The \"best\" estimates will be the $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ that minimize the MSE. Doing some Calculus you can derive that this gives the following best linear estimates for the $\\hat{\\beta}$s:\n",
    "$$\n",
    "\\hat{\\beta_1} = \\frac{\\sum_{i=1}^n\\left(rd_i - \\overline{rd}\\right)\\left(w_i - \\overline{w}\\right)}{\\sum_{i=1}^n\\left(rd_i - \\overline{rd}\\right)^2} = \\frac{\\text{cov}(rd,w)}{\\sigma^2_{rd}}, \\text{ and}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\hat{\\beta_0} = \\overline{w} - \\hat{\\beta_1}\\overline{rd}.\n",
    "$$\n",
    "These two formulas give the <i>least squares coefficient estimates</i> for simple linear regression.\n",
    "\n",
    "Let's do a little coding and calculate the least squares estimate for regressing wins on run differential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note you can get a column's variance using .var()\n",
    "## Note you can get a covariance matrix from a dataframe using .cov()\n",
    "\n",
    "# Get the means here\n",
    "w_mean = baseball_train.W.mean()\n",
    "rd_mean = baseball_train.RD.mean()\n",
    "\n",
    "\n",
    "# Get the covariance and variance\n",
    "cov = baseball_train[['W','RD']].cov().iloc[0,1]\n",
    "rd_var = baseball_train.RD.var()\n",
    "\n",
    "# Calculate beta_1_hat\n",
    "beta_1_hat = cov/rd_var\n",
    "\n",
    "# Calculate beta_0_hat\n",
    "beta_0_hat = w_mean - beta_1_hat * rd_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can produce a plot with the fitted line here\n",
    "## Now produce a plot with the samples and the fitted SLR line\n",
    "\n",
    "## Use the x as the input for your line, i.e. beta_0_hat + beta_1_hat*x\n",
    "min_rd = baseball_train.RD.min()\n",
    "max_rd = baseball_train.RD.max()\n",
    "padding = 20\n",
    "x = np.linspace(min_rd - padding,max_rd + padding,1000)\n",
    "\n",
    "\n",
    "\n",
    "## Sample Answer\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "# plt.scatter plots RD on the x and W on the y\n",
    "plt.scatter(baseball_train.RD, baseball_train.W, label = \"observations\")\n",
    "\n",
    "# Now add mean prediction line\n",
    "plt.plot(np.linspace(min_rd - padding,max_rd + padding,1000),\n",
    "            beta_0_hat + beta_1_hat*np.linspace(min_rd - padding,max_rd + padding,1000), 'k',\n",
    "            label=\"SLR Line\",\n",
    "            linewidth = 2)\n",
    "\n",
    "# Always good practice to label well when\n",
    "# presenting a figure to others\n",
    "# place an xlabel\n",
    "plt.xlabel(\"Run Differential\", fontsize =16)\n",
    "\n",
    "# place a ylabel\n",
    "plt.ylabel(\"Wins\", fontsize = 16)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# type this to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ML Aside\n",
    "\n",
    "MSE is just one example of what is called a <i>loss function</i> or <i>cost function</i>. In Machine Learning problems we often fit our models by minimizing the loss function. For example, to find the $\\beta_0$ and $\\beta_1$ estimates we minimized MSE. We'll see many examples of loss functions as we go along in the course.\n",
    "\n",
    "##### Aside Over\n",
    "\n",
    "## Break Time!\n",
    "\n",
    "Let's take another short break! I'll answer some questions via the chat, and you can feel free to check gmail or play a quick game of minesweeper. I'll warn you when we're ready to get going again.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Break Over!\n",
    "\n",
    "\n",
    "#### `sklearn` and `seaborn` Shortcuts\n",
    "\n",
    "Now that we did all that work let's see a couple of shortcuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Building with sklearn\n",
    "\n",
    "# first we import Linear Regression from sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make a model object\n",
    "slr = LinearRegression(copy_X = True)\n",
    "\n",
    "# Now we fit the model\n",
    "# first goes the input variables\n",
    "# Then the output variables\n",
    "# If the input is a 1-D vector you need to reshape it\n",
    "# Then you need to ravel() the output\n",
    "slr.fit(baseball_train['RD'].values.reshape(-1,1), baseball_train['W'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see the coefficients\n",
    "print(\"beta_1_hat is\", slr.coef_[0])\n",
    "print(\"beta_0_hat is\", slr.intercept_)\n",
    "\n",
    "print()\n",
    "\n",
    "# Let's compare that to what we computed\n",
    "print(\"We computed beta_1_hat to be\", beta_1_hat)\n",
    "print(\"We compute beta_0_hat to be\", beta_0_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make predictions like so\n",
    "min_rd = baseball_train.RD.min()\n",
    "max_rd = baseball_train.RD.max()\n",
    "padding = 20\n",
    "x = np.linspace(min_rd - padding,max_rd + padding,10)\n",
    "\n",
    "slr.predict(x.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` is <b>the</b> Python machine learning library. As we go throught the course we'll be relying heavily on `sklearn`. The pattern we just showed is the common `sklearn` pattern, import the model, make a model object, fit the object, then predict. To learn more about the `LinearRegression` object read the documentation here: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a>.\n",
    "\n",
    "Now let's introduce a nice plotting shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can have a nice plotting shortcut too\n",
    "\n",
    "# seaborn lmplot stands for \n",
    "# linear model plot\n",
    "# it makes a scatter plot and plots the regression plot over it\n",
    "# height controls the size of the plot\n",
    "# ci stands for confidence interval, we'll come back to that later\n",
    "sns.lmplot(data = baseball_train, x = 'RD', y = 'W', height = 10, ci=None)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Run Differential\", fontsize = 16)\n",
    "plt.ylabel(\"Wins\", fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`seaborn` is an excellent plotting library. We'll leave it to you to explore it separately. Here is the documentation page <a href=\"https://seaborn.pydata.org/index.html\">https://seaborn.pydata.org/index.html</a>, and here is a nice tutorial using pokemon data to help teach various plots, <a href=\"https://elitedatascience.com/python-seaborn-tutorial\">https://elitedatascience.com/python-seaborn-tutorial</a>.\n",
    "\n",
    "\n",
    "### Interpreting the Coeficient of SLR\n",
    "\n",
    "A nice thing about SLR is that we can interpret the $\\beta_1$ coefficient in a meaningful way. If for example $\\hat{\\beta_1} = 2$ in the run differential problem we could say that for a $1$ point increase in run differential we estimate an increase of $2$ wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A print statement that interprets the \n",
    "# best linear estimate of beta_1 here\n",
    "print(\"A 1 point increase in run differential gives an estimated\",\n",
    "         np.round(beta_1_hat,4),\n",
    "          \"additional wins.\")\n",
    "\n",
    "\n",
    "print(\"So we estimate that a team needs a\",\n",
    "         np.round(1/beta_1_hat,1),\n",
    "          \"point run differential increase for 1 additional win.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing Performance\n",
    "\n",
    "Before setting you loose to work on a Simple Linear Regression problem of your own we can see how to measure the MSE of our model on both the training data and test data.\n",
    "\n",
    "##### Training Data\n",
    "\n",
    "It is often useful to compare how good the model fit training data when we are trying to choose a best model. Since there is no other model to choose from, we'll just get some practice coding in python below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to calculate MSE on the training data\n",
    "# here, you may use either a by hand calculation or\n",
    "# sklearn\n",
    "## Sample Answer\n",
    "def mse(y,y_pred,r):\n",
    "    return np.round(np.sum((y-y_pred)**2)/len(y),r)\n",
    "\n",
    "y_train = baseball_train.W.values\n",
    "y_train_pred = slr.predict(baseball_train.RD.values.reshape(-1,1))\n",
    "\n",
    "print(\"The training MSE is\",mse(y_train,y_train_pred,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Data\n",
    "\n",
    "Since we won't be doing any additional model improvements or model comparisons go ahead and calculate how well we did on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to calculate MSE on the training data\n",
    "# here, you may use either a by hand calculation or\n",
    "# sklearn\n",
    "## Sample Answer\n",
    "y_test = baseball_test.W.values\n",
    "y_test_pred = slr.predict(baseball_test.RD.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "print(\"The training MSE is\",mse(y_test,y_test_pred,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Now it's your turn to practice building a SLR model.\n",
    "\n",
    "We'll look at the `carseats` data set from Introduction to Statistical Learning in R. This looks at various variables related to the sales of child car seats at $400$ stores. Each row is a store. The thing we'd like to predict is `Sales`. We'll return to this data set in later notebooks. For now try to build a SLR model regressing `Sales` on `Price`. Once you have your model built, interpret the outcome and produce a measure of how good your model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data set here\n",
    "carseats = pd.read_csv(\"carseats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What do you need to do first before exploring the data?\n",
    "## Do That here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now explore the data\n",
    "## plot Price vs Sales and see if \n",
    "## a linear regression model makes sense.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you think it is appropriate fit the model here\n",
    "## You may use sklearn or by hand\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a new plot with your\n",
    "## Regression Line here\n",
    "## Does it look like a good fit?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpret the model here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide measures of goodness here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See you in Notebook 2!\n",
    "\n",
    "That's it for this notebook. You learned:\n",
    "<ul>\n",
    "    <li>what SLR is,</li>\n",
    "    <li>how to fit it,</li>\n",
    "    <li>and how to interpret the output.</li>\n",
    "</ul>    \n",
    "Along the way we introduced ML concepts like:\n",
    "<ul>\n",
    "    <li>statistical learning,</li>\n",
    "    <li>train test splits,</li>\n",
    "    <li>and loss functions.</li>\n",
    "</ul>\n",
    "    \n",
    "Next we'll wrap up SLR with a few odds and ends. Then we'll move on to extensions on Simple Linear Regression that will allow for even better models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
